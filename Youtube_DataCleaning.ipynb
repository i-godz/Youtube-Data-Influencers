{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***1- Importing Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***2- Data Preprocessing & Feature Engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, specifying the data types for each column\n",
    "youtube_data = pd.read_csv('/Users/godzilla/Desktop/Selected Topics-2/Project/youtube_data.csv', low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***2.1- Channel Data Preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "new_column_names = {\n",
    "    'video_id': 'Video_ID',\n",
    "    'channelTitle': 'Channel_Name',\n",
    "    'title': 'Title',\n",
    "    'description': 'Description',\n",
    "    'tags': 'Tags',\n",
    "    'publishedAt': 'Published_At',\n",
    "    'categoryId': 'Category_ID',\n",
    "    'defaultAudioLanguage': 'Audio_Language',\n",
    "    'viewCount': 'View_Count',\n",
    "    'likeCount': 'Like_Count',\n",
    "    'dislikeCount': 'Dislike_Count',\n",
    "    'commentCount': 'Comment_Count',\n",
    "    'duration': 'Duration',\n",
    "    'definition': 'Definition',\n",
    "    'caption': 'Caption',\n",
    "}\n",
    "\n",
    "youtube_data.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2740 entries, 0 to 2739\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Video_ID        2740 non-null   object\n",
      " 1   Channel_Name    2740 non-null   object\n",
      " 2   Title           2740 non-null   object\n",
      " 3   Description     2599 non-null   object\n",
      " 4   Tags            2740 non-null   object\n",
      " 5   Published_At    2740 non-null   object\n",
      " 6   Category_ID     2740 non-null   int64 \n",
      " 7   Audio_Language  2740 non-null   object\n",
      " 8   thumbnails      2740 non-null   object\n",
      " 9   View_Count      2740 non-null   int64 \n",
      " 10  Like_Count      2740 non-null   int64 \n",
      " 11  Dislike_Count   2740 non-null   int64 \n",
      " 12  Comment_Count   2740 non-null   int64 \n",
      " 13  Duration        2740 non-null   object\n",
      " 14  Definition      2740 non-null   object\n",
      " 15  Caption         2740 non-null   bool  \n",
      "dtypes: bool(1), int64(5), object(10)\n",
      "memory usage: 323.9+ KB\n"
     ]
    }
   ],
   "source": [
    "youtube_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert count columns to numeric columns\n",
    "numeric_columns = ['View_Count', 'Like_Count', 'Comment_Count', 'Category_ID', 'Dislike_Count']\n",
    "youtube_data[numeric_columns] = youtube_data[numeric_columns].apply(pd.to_numeric, errors='coerce', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "youtube_data['Duration'] = youtube_data['Duration'].apply(lambda x: pd.to_timedelta(x).total_seconds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_data['Audio_Language'] = youtube_data['Audio_Language'].replace({\n",
    "    'en': 'English',\n",
    "    'en-US': 'English',\n",
    "    'ar': 'Arabic',\n",
    "    'en-GB': 'English',\n",
    "    'en-IN': 'English',\n",
    "    'hi': 'Hindi'\n",
    "})\n",
    "\n",
    "# Create a dictionary to map channel names to audio languages\n",
    "channel_audio_mapping = {\n",
    "    \"Ken Jee\": \"English\",\n",
    "    \"Ranesh Guruparan\": \"English\",\n",
    "    \"Youssef Hosni\": \"Arabic\",\n",
    "    \"Sundas Khalid\": \"English\",\n",
    "    \"edrea\": \"English\",\n",
    "    \"Mohamed Al Assaal - اتعلم مع العسال\": \"Arabic\",\n",
    "    \"Deena Gergis\": \"Arabic\",\n",
    "    \"Lore So What\": \"English\",\n",
    "    \"Thu Vu data analytics\": \"English\",\n",
    "    \"Data With Mo\": \"English\",\n",
    "    \"techTFQ\": \"English\",\n",
    "    \"Learn with Lukas\": \"English\",\n",
    "    \"Alex The Analyst\": \"English\",\n",
    "    \"codebasics\": \"English\",\n",
    "    \"Mustafa Othman\": \"Arabic\",\n",
    "    \"Justin Shin\": \"English\",\n",
    "}\n",
    "\n",
    "# Update Audio_Language column based on the dictionary mapping for null values\n",
    "for channel_name, audio_language in channel_audio_mapping.items():\n",
    "    condition = (youtube_data[\"Channel_Name\"] == channel_name) & (youtube_data[\"Audio_Language\"].isnull())\n",
    "    youtube_data.loc[condition, \"Audio_Language\"] = audio_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_data[\"Comment_Count\"].fillna(0, inplace=True)\n",
    "youtube_data[\"Like_Count\"].fillna(0, inplace=True)\n",
    "\n",
    "youtube_data[\"Tags\"].fillna(\"Not Specified\", inplace=True)\n",
    "youtube_data[\"Description\"].fillna(\"Not Specified\", inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***5.2- Features Engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map category IDs to their text categories\n",
    "category_id_to_name = {\n",
    "    28: \"Science & Technology\",\n",
    "    24: \"Entertainment\",\n",
    "    22: \"People & Blogs\",\n",
    "    27: \"Education\",\n",
    "    26: \"Howto & Style\",\n",
    "    19: \"Travel & Events\",\n",
    "    1: \"Film & Animation\",\n",
    "    23: \"Comedy\",\n",
    "    25: \"News & Politics\",\n",
    "    20: \"Gaming\",\n",
    "    17: \"Sports\"\n",
    "}\n",
    "\n",
    "# Replace the category IDs with their text categories\n",
    "youtube_data[\"Category_Name\"] = youtube_data[\"Category_ID\"].replace(category_id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of tags\n",
    "youtube_data['Tags_Count'] = youtube_data['Tags'].apply(lambda x: 0 if x == 'Not Specified' else len(x.split(\",\")))\n",
    "\n",
    "# Title character length\n",
    "youtube_data['Title_Length'] = youtube_data['Title'].apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the engagement rate\n",
    "youtube_data['Engagement_rate'] = round((youtube_data['Like_Count'] + youtube_data['Comment_Count']) / youtube_data['View_Count'] * 100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize videos\n",
    "def categorize_videos(row):\n",
    "    if row[\"Duration\"] <= 60:\n",
    "        return \"Short\"\n",
    "    elif row[\"Duration\"] > 60 and row[\"Duration\"] <= 3600:\n",
    "        return \"Regular Content\" \n",
    "    else: \n",
    "        return \"Podcast/Tutorials\"\n",
    "\n",
    "# Apply the categorization function to create a new Category column\n",
    "youtube_data[\"Video_Category\"] = youtube_data.apply(categorize_videos, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the current date as a timezone-aware datetime\n",
    "current_date = pd.Timestamp.now(tz='UTC')\n",
    "\n",
    "# Convert the 'Published_At' column to a pandas datetime\n",
    "youtube_data['Published_At'] = pd.to_datetime(youtube_data['Published_At'])\n",
    "\n",
    "# Calculate the difference between current date and 'Published_At' in days\n",
    "youtube_data['Days_Since_Published'] = (current_date - youtube_data['Published_At']).dt.days\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the popularity score using the given formula\n",
    "youtube_data['Popularity_Score'] = (\n",
    "    (youtube_data['View_Count'] * 2) +\n",
    "    youtube_data['Like_Count'] - youtube_data['Dislike_Count'] +\n",
    "    (youtube_data['Comment_Count'] / youtube_data['Days_Since_Published'])\n",
    ")\n",
    "\n",
    "# Round the popularity_score values to 2 decimal places\n",
    "youtube_data['Popularity_Score'] = youtube_data['Popularity_Score'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the shearability score using the formula\n",
    "youtube_data['Shearability_Score'] = (youtube_data['View_Count'] * 2) + \\\n",
    "                                     youtube_data['Like_Count'] - \\\n",
    "                                     youtube_data['Dislike_Count'] + \\\n",
    "                                     (youtube_data['Comment_Count'] / youtube_data['Days_Since_Published']) * \\\n",
    "                                     youtube_data['Engagement_rate']\n",
    "\n",
    "# Round the Shearability_Score values to 2 decimal places\n",
    "youtube_data['Shearability_Score'] = youtube_data['Shearability_Score'].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video_ID</th>\n",
       "      <th>Channel_Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Published_At</th>\n",
       "      <th>Category_ID</th>\n",
       "      <th>Audio_Language</th>\n",
       "      <th>thumbnails</th>\n",
       "      <th>View_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Category_Name</th>\n",
       "      <th>Tags_Count</th>\n",
       "      <th>Title_Length</th>\n",
       "      <th>Engagement_rate</th>\n",
       "      <th>Video_Category</th>\n",
       "      <th>Days_Since_Published</th>\n",
       "      <th>Popularity_Score</th>\n",
       "      <th>Shearability_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l14K2EnD548</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>AI Will Replace Tech Jobs: From ex-FAANG Softw...</td>\n",
       "      <td>50 job interview questions &amp; answers 👉🏼 https:...</td>\n",
       "      <td>['data science', 'self-taugh data scientist', ...</td>\n",
       "      <td>2023-08-07 14:10:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/l1...</td>\n",
       "      <td>3736</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>4.26</td>\n",
       "      <td>Regular Content</td>\n",
       "      <td>1</td>\n",
       "      <td>7631.00</td>\n",
       "      <td>7719.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ssLi7Ll0I0</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>How Much Money I Made as Data Engineer? (3 yea...</td>\n",
       "      <td>Resume &amp; Cover Letter template (free) 👉🏼 https...</td>\n",
       "      <td>['data science', 'data scientist', 'self-taugh...</td>\n",
       "      <td>2023-07-28 14:10:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/7s...</td>\n",
       "      <td>16280</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Regular Content</td>\n",
       "      <td>11</td>\n",
       "      <td>32853.73</td>\n",
       "      <td>32856.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xr68cbOxvBs</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>How to learn Python FAST with ChatGPT and Bard?</td>\n",
       "      <td>Try Quadratic for FREE 👉🏼 https://QuadraticHQ....</td>\n",
       "      <td>['data science', 'data scientist', 'self-taugh...</td>\n",
       "      <td>2023-07-10 14:10:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/xr...</td>\n",
       "      <td>325057</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>1.18</td>\n",
       "      <td>Regular Content</td>\n",
       "      <td>29</td>\n",
       "      <td>653845.41</td>\n",
       "      <td>653846.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mLP4kdk3DoI</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>Will AI Replace Data Scientists?</td>\n",
       "      <td>Excel graphs template (free) 👉🏼 https://clickh...</td>\n",
       "      <td>['data science', 'data scientist', 'self-taugh...</td>\n",
       "      <td>2023-06-29 14:12:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/mL...</td>\n",
       "      <td>17758</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>3.42</td>\n",
       "      <td>Regular Content</td>\n",
       "      <td>40</td>\n",
       "      <td>36054.75</td>\n",
       "      <td>36058.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>znouY2A61WI</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>How to code Python FAST for Data Analysis: Bar...</td>\n",
       "      <td>Click to read full AI Trend Report (FREE) 👉🏼 h...</td>\n",
       "      <td>['data science', 'data scientist', 'self-taugh...</td>\n",
       "      <td>2023-06-16 14:10:01+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/zn...</td>\n",
       "      <td>22949</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>True</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2.22</td>\n",
       "      <td>Regular Content</td>\n",
       "      <td>53</td>\n",
       "      <td>46369.74</td>\n",
       "      <td>46370.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>YrubB5aXStY</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>Data Science with NO coding 😳👨🏼‍💻</td>\n",
       "      <td>Full Video Here 👉🏼 youtu.be/VrdnBxx8BBI\\n\\nCou...</td>\n",
       "      <td>['data viz by luke', 'business intelligence', ...</td>\n",
       "      <td>2023-01-18 16:00:14+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/Yr...</td>\n",
       "      <td>28704</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>5.55</td>\n",
       "      <td>Short</td>\n",
       "      <td>202</td>\n",
       "      <td>58968.16</td>\n",
       "      <td>58968.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>LDds33bJy6g</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>Degrees vs. Experience in Data Science 📜 🆚 📊</td>\n",
       "      <td>Full Video Here 👉🏼 youtu.be/VrdnBxx8BBI\\n\\nRob...</td>\n",
       "      <td>['data viz by luke', 'business intelligence', ...</td>\n",
       "      <td>2023-01-16 16:00:18+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/LD...</td>\n",
       "      <td>29202</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>6.59</td>\n",
       "      <td>Short</td>\n",
       "      <td>204</td>\n",
       "      <td>60297.16</td>\n",
       "      <td>60298.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>cPbWjaLPHkc</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>Data Analyst's first course 🧑‍💻</td>\n",
       "      <td>📜 Google Data Analytics Certificate 👉🏼  lukeb....</td>\n",
       "      <td>['data viz by luke', 'business intelligence', ...</td>\n",
       "      <td>2023-01-13 16:00:20+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/cP...</td>\n",
       "      <td>13693</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>11.06</td>\n",
       "      <td>Short</td>\n",
       "      <td>207</td>\n",
       "      <td>28875.12</td>\n",
       "      <td>28876.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0qcsqdeDbc0</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>Data Analysts are lowest paid in Data Science 💸🥵</td>\n",
       "      <td>Full Video Here 👉🏼 https://youtu.be/NAuuqdzC_r...</td>\n",
       "      <td>['data viz by luke', 'business intelligence', ...</td>\n",
       "      <td>2023-01-11 16:00:00+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/0q...</td>\n",
       "      <td>57276</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>5.67</td>\n",
       "      <td>Short</td>\n",
       "      <td>209</td>\n",
       "      <td>117741.29</td>\n",
       "      <td>117742.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>i0B9TSum6bg</td>\n",
       "      <td>Luke Barousse</td>\n",
       "      <td>Day in the life of a Data Analyst 🤓📊</td>\n",
       "      <td>Full Video Here 👉🏼 https://youtu.be/VrdnBxx8BB...</td>\n",
       "      <td>['data viz by luke', 'business intelligence', ...</td>\n",
       "      <td>2023-01-10 15:56:59+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>English</td>\n",
       "      <td>{'default': {'url': 'https://i.ytimg.com/vi/i0...</td>\n",
       "      <td>64430</td>\n",
       "      <td>...</td>\n",
       "      <td>hd</td>\n",
       "      <td>False</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>8.88</td>\n",
       "      <td>Short</td>\n",
       "      <td>210</td>\n",
       "      <td>134530.25</td>\n",
       "      <td>134532.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Video_ID   Channel_Name  \\\n",
       "0    l14K2EnD548  Sundas Khalid   \n",
       "1    7ssLi7Ll0I0  Sundas Khalid   \n",
       "2    xr68cbOxvBs  Sundas Khalid   \n",
       "3    mLP4kdk3DoI  Sundas Khalid   \n",
       "4    znouY2A61WI  Sundas Khalid   \n",
       "..           ...            ...   \n",
       "195  YrubB5aXStY  Luke Barousse   \n",
       "196  LDds33bJy6g  Luke Barousse   \n",
       "197  cPbWjaLPHkc  Luke Barousse   \n",
       "198  0qcsqdeDbc0  Luke Barousse   \n",
       "199  i0B9TSum6bg  Luke Barousse   \n",
       "\n",
       "                                                 Title  \\\n",
       "0    AI Will Replace Tech Jobs: From ex-FAANG Softw...   \n",
       "1    How Much Money I Made as Data Engineer? (3 yea...   \n",
       "2      How to learn Python FAST with ChatGPT and Bard?   \n",
       "3                     Will AI Replace Data Scientists?   \n",
       "4    How to code Python FAST for Data Analysis: Bar...   \n",
       "..                                                 ...   \n",
       "195                  Data Science with NO coding 😳👨🏼‍💻   \n",
       "196       Degrees vs. Experience in Data Science 📜 🆚 📊   \n",
       "197                    Data Analyst's first course 🧑‍💻   \n",
       "198   Data Analysts are lowest paid in Data Science 💸🥵   \n",
       "199               Day in the life of a Data Analyst 🤓📊   \n",
       "\n",
       "                                           Description  \\\n",
       "0    50 job interview questions & answers 👉🏼 https:...   \n",
       "1    Resume & Cover Letter template (free) 👉🏼 https...   \n",
       "2    Try Quadratic for FREE 👉🏼 https://QuadraticHQ....   \n",
       "3    Excel graphs template (free) 👉🏼 https://clickh...   \n",
       "4    Click to read full AI Trend Report (FREE) 👉🏼 h...   \n",
       "..                                                 ...   \n",
       "195  Full Video Here 👉🏼 youtu.be/VrdnBxx8BBI\\n\\nCou...   \n",
       "196  Full Video Here 👉🏼 youtu.be/VrdnBxx8BBI\\n\\nRob...   \n",
       "197  📜 Google Data Analytics Certificate 👉🏼  lukeb....   \n",
       "198  Full Video Here 👉🏼 https://youtu.be/NAuuqdzC_r...   \n",
       "199  Full Video Here 👉🏼 https://youtu.be/VrdnBxx8BB...   \n",
       "\n",
       "                                                  Tags  \\\n",
       "0    ['data science', 'self-taugh data scientist', ...   \n",
       "1    ['data science', 'data scientist', 'self-taugh...   \n",
       "2    ['data science', 'data scientist', 'self-taugh...   \n",
       "3    ['data science', 'data scientist', 'self-taugh...   \n",
       "4    ['data science', 'data scientist', 'self-taugh...   \n",
       "..                                                 ...   \n",
       "195  ['data viz by luke', 'business intelligence', ...   \n",
       "196  ['data viz by luke', 'business intelligence', ...   \n",
       "197  ['data viz by luke', 'business intelligence', ...   \n",
       "198  ['data viz by luke', 'business intelligence', ...   \n",
       "199  ['data viz by luke', 'business intelligence', ...   \n",
       "\n",
       "                 Published_At  Category_ID Audio_Language  \\\n",
       "0   2023-08-07 14:10:00+00:00           28        English   \n",
       "1   2023-07-28 14:10:00+00:00           28        English   \n",
       "2   2023-07-10 14:10:00+00:00           28        English   \n",
       "3   2023-06-29 14:12:00+00:00           28        English   \n",
       "4   2023-06-16 14:10:01+00:00           28        English   \n",
       "..                        ...          ...            ...   \n",
       "195 2023-01-18 16:00:14+00:00           28        English   \n",
       "196 2023-01-16 16:00:18+00:00           28        English   \n",
       "197 2023-01-13 16:00:20+00:00           28        English   \n",
       "198 2023-01-11 16:00:00+00:00           28        English   \n",
       "199 2023-01-10 15:56:59+00:00           28        English   \n",
       "\n",
       "                                            thumbnails  View_Count  ...  \\\n",
       "0    {'default': {'url': 'https://i.ytimg.com/vi/l1...        3736  ...   \n",
       "1    {'default': {'url': 'https://i.ytimg.com/vi/7s...       16280  ...   \n",
       "2    {'default': {'url': 'https://i.ytimg.com/vi/xr...      325057  ...   \n",
       "3    {'default': {'url': 'https://i.ytimg.com/vi/mL...       17758  ...   \n",
       "4    {'default': {'url': 'https://i.ytimg.com/vi/zn...       22949  ...   \n",
       "..                                                 ...         ...  ...   \n",
       "195  {'default': {'url': 'https://i.ytimg.com/vi/Yr...       28704  ...   \n",
       "196  {'default': {'url': 'https://i.ytimg.com/vi/LD...       29202  ...   \n",
       "197  {'default': {'url': 'https://i.ytimg.com/vi/cP...       13693  ...   \n",
       "198  {'default': {'url': 'https://i.ytimg.com/vi/0q...       57276  ...   \n",
       "199  {'default': {'url': 'https://i.ytimg.com/vi/i0...       64430  ...   \n",
       "\n",
       "     Definition  Caption         Category_Name  Tags_Count Title_Length  \\\n",
       "0            hd     True  Science & Technology          28            9   \n",
       "1            hd     True  Science & Technology          27           14   \n",
       "2            hd     True  Science & Technology          28            9   \n",
       "3            hd    False  Science & Technology          27            5   \n",
       "4            hd     True  Science & Technology          27           11   \n",
       "..          ...      ...                   ...         ...          ...   \n",
       "195          hd    False  Science & Technology          18            6   \n",
       "196          hd    False  Science & Technology          18            9   \n",
       "197          hd    False  Science & Technology          18            5   \n",
       "198          hd    False  Science & Technology          18            9   \n",
       "199          hd    False  Science & Technology          18            9   \n",
       "\n",
       "     Engagement_rate   Video_Category  Days_Since_Published  Popularity_Score  \\\n",
       "0               4.26  Regular Content                     1           7631.00   \n",
       "1               1.97  Regular Content                    11          32853.73   \n",
       "2               1.18  Regular Content                    29         653845.41   \n",
       "3               3.42  Regular Content                    40          36054.75   \n",
       "4               2.22  Regular Content                    53          46369.74   \n",
       "..               ...              ...                   ...               ...   \n",
       "195             5.55            Short                   202          58968.16   \n",
       "196             6.59            Short                   204          60297.16   \n",
       "197            11.06            Short                   207          28875.12   \n",
       "198             5.67            Short                   209         117741.29   \n",
       "199             8.88            Short                   210         134530.25   \n",
       "\n",
       "     Shearability_Score  \n",
       "0               7719.02  \n",
       "1              32856.37  \n",
       "2             653846.03  \n",
       "3              36058.98  \n",
       "4              46370.63  \n",
       "..                  ...  \n",
       "195            58968.88  \n",
       "196            60298.03  \n",
       "197            28876.34  \n",
       "198           117742.65  \n",
       "199           134532.20  \n",
       "\n",
       "[200 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "youtube_data.head(200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***3- Comments Data Preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m comments_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/Users/godzilla/Desktop/Selected Topics-2/Project/youtube_comments_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:235\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[1;32m    234\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m    236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:790\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "comments_data = pd.read_csv('/Users/godzilla/Desktop/Selected Topics-2/Project/youtube_comments_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_comments(comments_data):\n",
    "    all_comments = []\n",
    "\n",
    "    for index, row in comments_data.iterrows():\n",
    "        vidid = row['video_id']\n",
    "        comments = row['comments'].split(',')\n",
    "        for comment in comments:\n",
    "            all_comments.append({'vidid': vidid, 'comment': comment.strip()})\n",
    "\n",
    "    return pd.DataFrame(all_comments)\n",
    "\n",
    "# Separate comments for the DataFrame\n",
    "separated_comments = separate_comments(comments_data)\n",
    "    \n",
    "# Display the resulting DataFrame\n",
    "print(separated_comments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data[\"comments\"] = comments_data[\"comments\"].str.replace('[\\[\\]]', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
